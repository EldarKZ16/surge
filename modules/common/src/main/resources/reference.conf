app {
  environment = "development"
  environment = ${?APP_ENVIRONMENT}
}

kafka {
  streams {
    # Clean up any Kafka Streams persistent state on startup, causing a full rebuild of any persisted state stores.
    # This is mostly useful if you manually change something in Kafka and Kafka Streams does not know how to pick up
    # where it left off - i.e. changing number of partitions, deleting and recreating a topic, manually changing
    # consumer offsets for this services consumer group, etc...
    wipe-state-on-start = false
    wipe-state-on-start = ${?KAFKA_STREAMS_CLEAN_ON_START}

    # Kafka streams commit interval. Kafka Streams will wait a max of this amount of time before committing results/flushing
    # KTables. In general, this is the delay an application will see before a state snapshot written to Kafka becomes available
    # in the aggregate state store KTable.  Increasing this gives better throughput but improves latency, decreasing gives lower
    # latency but worse throughput.
    commit-interval-ms = 3000
    commit-interval-ms = ${?KAFKA_STREAMS_COMMIT_INTERVAL_MS}

    # Number of standby replicas of state stores/Kafka Streams processors to keep. Additional standbys use
    # additional resources, but allow for better fault tolerance
    num-standby-replicas = 0
    num-standby-replicas = ${?KAFKA_STREAMS_NUM_STANDBY_REPLICAS}

    # Percent of on-heap memory to use for the Kafka Streams cache
    cache-heap-percentage = 0.25
    cache-heap-percentage = ${?KAFKA_STREAMS_CACHE_HEAP_PERCENT}

    state-dir = "/tmp/kafka-streams"
    state-dir = ${?KAFKA_STREAMS_STATE_DIR}

    # TODO If we run mutliple integration tests on one node at the same time, Kafka Streams crashes because it can't get exclusive
    #      ownership of the state store directories.  Setting this to true will set a random consumer group for each instance so they each
    #      get their own state directory.  Is this config setting the best way to do this?
    test-mode = false

    # RocksDB is the underlying backing for the aggregate KTable state store.  You can tune performance of the
    # state store by tuning rocksdb.  The defaults for these are generally ok, and it is recommended to enable
    # dumping statistics to get a better view of the underlying performance before and while tuning settings here.
    rocks-db {
      # Number of concurrent compactions that should be run in parallel by rocksdb
      compaction-parallelism = 2
      compaction-parallelism = ${?KAFKA_STREAMS_ROCKSDB_COMPACTION_PARALLELISM}

      # Used for debug and performance tuning, setting this to true will cause rocksdb to print
      # performance statistics to a log file in the same directory as rocksdb uses to spill sstfiles to disk
      dump-statistics = false
      dump-statistics = ${?KAFKA_STREAMS_ROCKSDB_DUMP_STATISTICS}

      # If dump-statistics is true, this is the interval at which statistics will be dumped by
      # rocksdb to the log file
      statistics-interval-seconds = 600
      statistics-interval-seconds = ${?KAFKA_STREAMS_ROCKSDB_STATISTICS_INTERVAL_SECONDS}
    }

    replay {
      reset-topic-timeout = 30 seconds
      reset-topic-timeout = ${?KAFKA_STREAMS_REPLAY_RESET_TOPIC_TIMEOUT}
      entire-process-timeout = 60 seconds
      entire-process-timeout = ${?KAFKA_STREAMS_REPLAY_TIMEOUT}
    }
  }
}

surge {
  # When enabled, bumps all the timeouts to 1000x their normal values.  Not recommended for actually running, as failure detection
  # becomes nearly non-existent, but is useful for stepping through the debugger to trace code
  debug-mode-timeouts-enabled = false

  state-store-actor {
    # Amount of time to wait when sending a command to an aggregate before considering it to have timed out.
    ask-timeout = 30 seconds
    ask-timeout = ${?STATE_STORE_ACTOR_ASK_TIMEOUT}
    fetch-state-retry-interval = 3 seconds
    fetch-state-rety-interval = ${?STATE_FETCH_INTERVAL}
    initialize-state-retry-interval = 250 milliseconds
    initialize-state-retry-interval = ${?STATE_INIT_RETRY_INTERVAL}
    max-initialization-attempts = 5
    max-initialization-attempts = ${?STATE_MAX_INIT_ATTEMPTS}
    backoff {
      min-backoff = 3 seconds
      min-backoff = ${?STATE_STORE_ACTOR_BACKOFF_MIN}
      max-backoff = 30 seconds
      max-backoff = ${?STATE_STORE_ACTOR_BACKOFF_MAX}
      random-factor = 0.2
      random-factor = ${?STATE_STORE_ACTOR_BACKOFF_RANDOM}
      max-retries = 10
      max-retries = ${?STATE_STORE_ACTOR_BACKOFF_RETRIES}
    }
  }

  aggregate-actor {
    # Amount of time to keep an aggregate in memory if new commands for that aggregate are not being sent/processed.
    # It is recommended to keep this value higher than your setting for kafka.streams.commit-interval-ms, otherwise
    # quickly sending messages to an actor no longer in memory could incur a delay in actor initialization.
    idle-timeout = 30 seconds
    idle-timeout = ${?AGGREGATE_ACTOR_IDLE_TIMEOUT}

    # Amount of time to wait when sending a command to an aggregate before considering it to have timed out.
    ask-timeout = 30 seconds
    ask-timeout = ${?AGGREGATE_ACTOR_ASK_TIMEOUT}

    publish-failure-max-retries = 1
    publish-failure-max-retries = ${?SURGE_AGGREGATE_ACTOR_PUBLISH_FAILURE_MAX_RETRIES}
  }

  producer {
    publish-timeout = 15 seconds
    publish-timeout = ${?SURGE_PRODUCER_PUBLISH_TIMEOUT}

    enable-kafka-metrics = true
    enable-kafka-metrics = ${?SURGE_PRODUCER_ENABLE_KAFKA_METRICS}
  }

  kafka-streams {
    state-store-plugin = "rocksdb"

    enable-kafka-metrics = true
    enable-kafka-metrics = ${?SURGE_KAFKA_STREAMS_ENABLE_KAFKA_METRICS}
  }

  kafka-event-source {
    committer {
      max-batch = 1000
      max-batch = ${?SURGE_KAFKA_EVENT_SOURCE_COMMITTER_MAX_BATCH}

      max-interval = 10s
      max-interval = ${?SURGE_KAFKA_EVENT_SOURCE_COMMITTER_MAX_INTERVAL}

      parallelism = 100
      parallelism = ${?SURGE_KAFKA_EVENT_SOURCE_COMMITTER_PARALLELISM}
    }

    consumer {
      auto-offset-reset = "earliest"
      auto-offset-reset = ${?SURGE_KAFKA_EVENT_SOURCE_CONSUMER_AUTO_OFFSET_RESET}

      session-timeout = 10 seconds
      session-timeout = ${?SURGE_KAFKA_EVENT_SOURCE_CONSUMER_SESSION_TIMEOUT}

      partition-assignor = "range"
      partition-assignor = ${?SURGE_KAFKA_EVENT_SOURCE_CONSUMER_PARTITION_ASSIGNOR}
    }

    backoff {
      min = 1 second
      min = ${?SURGE_KAFKA_EVENT_SOURCE_BACKOFF_MIN}

      max = 10 seconds
      max = ${?SURGE_KAFKA_EVENT_SOURCE_BACKOFF_MAX}

      random-factor = 0.1
      random-factor = ${?SURGE_KAFKA_EVENT_SOURCE_BACKOFF_RANDOM_FACTOR}
    }

    kafka-metric-fetch-timeout = 15 seconds
    kafka-metric-fetch-timeout = ${?SURGE_KAFKA_EVENT_SOURCE_METRIC_FETCH_TIMEOUT}

    enable-kafka-metrics = true
    enable-kafka-metrics = ${?SURGE_KAFKA_EVENT_SOURCE_ENABLE_KAFKA_METRICS}
  }

  kafka-reuse-consumer-id = false
  kafka-reuse-consumer-id = ${?SURGE_KAFKA_REUSE_CONSUMER_GROUP_ID}
}

rocksdb {
  plugin-class = "surge.kafka.streams.RocksDBPersistencePlugin"
}

ulti {
  dr-standby-enabled = false
  dr-standby-enabled = ${?SURGE_ENABLE_DR_STANDBY}
}
